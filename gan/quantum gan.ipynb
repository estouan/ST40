{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwDxq-PpIC-j",
        "outputId": "fc7bb61b-8e7f-4f57-f71d-73f34c497c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.3.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit-1.3.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.9 pbr-6.1.0 qiskit-1.3.1 rustworkx-0.15.1 stevedore-5.4.0 symengine-0.13.0\n",
            "Collecting qiskit_aer\n",
            "  Downloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.13.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (5.9.5)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.1.0->qiskit_aer) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit_aer) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit_aer) (1.3.0)\n",
            "Downloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit_aer\n",
            "Successfully installed qiskit_aer-0.15.1\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: qiskit>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (75.1.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.9)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.0->qiskit_machine_learning) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.0->qiskit_machine_learning) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.0->qiskit_machine_learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit_machine_learning\n",
            "Successfully installed qiskit_machine_learning-0.8.1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_aer\n",
        "!pip install qiskit_machine_learning\n",
        "import os\n",
        "import time\n",
        "from qiskit.quantum_info import Pauli\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import PauliFeatureMap, RealAmplitudes\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from sympy.core.random import randint\n",
        "from torch.sparse import log_softmax\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import functional as F\n",
        "import torch.autograd as autograd\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit import *\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit import transpile\n",
        "from qiskit_aer import Aer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjdac3ZwHq_x"
      },
      "outputs": [],
      "source": [
        "class quantum_layer:\n",
        "    def __init__(self,nbqbitin,nbqbitout):\n",
        "        self.nbqbitin = nbqbitin\n",
        "        self.nbqbitout = nbqbitout\n",
        "\n",
        "        self.circuit = self.create_circuit(4)\n",
        "    def create_circuit(self,nbqbits=8):\n",
        "        def conv_circuit(params):\n",
        "            target = QuantumCircuit(2)\n",
        "            target.rz(-np.pi / 2, 1)\n",
        "            target.cx(1, 0)\n",
        "            target.rz(params[0], 0)\n",
        "            target.ry(params[1], 1)\n",
        "            target.cx(0, 1)\n",
        "            target.ry(params[2], 1)\n",
        "            target.cx(1, 0)\n",
        "            target.rz(np.pi / 2, 0)\n",
        "            return target\n",
        "\n",
        "        def conv_layer(num_qubits, param_prefix):\n",
        "            qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
        "            qubits = list(range(num_qubits))\n",
        "            param_index = 0\n",
        "            params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
        "            for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
        "                qc = qc.compose(conv_circuit(params[param_index: (param_index + 3)]), [q1, q2])\n",
        "                qc.barrier()\n",
        "                param_index += 3\n",
        "            for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
        "                qc = qc.compose(conv_circuit(params[param_index: (param_index + 3)]), [q1, q2])\n",
        "                qc.barrier()\n",
        "                param_index += 3\n",
        "\n",
        "            qc_inst = qc.to_instruction()\n",
        "\n",
        "            qc = QuantumCircuit(num_qubits)\n",
        "            qc.append(qc_inst, qubits)\n",
        "            return qc\n",
        "\n",
        "        def pool_circuit(params):\n",
        "            target = QuantumCircuit(2)\n",
        "            target.rz(-np.pi / 2, 1)\n",
        "            target.cx(1, 0)\n",
        "            target.rz(params[0], 0)\n",
        "            target.ry(params[1], 1)\n",
        "            target.cx(0, 1)\n",
        "            target.ry(params[2], 1)\n",
        "\n",
        "            return target\n",
        "\n",
        "        def pool_layer(sources, sinks, param_prefix):\n",
        "            num_qubits = len(sources) + len(sinks)\n",
        "            qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
        "            param_index = 0\n",
        "            params = ParameterVector(param_prefix, length=num_qubits // 2 * 3)\n",
        "            for source, sink in zip(sources, sinks):\n",
        "                qc = qc.compose(pool_circuit(params[param_index: (param_index + 3)]), [source, sink])\n",
        "                qc.barrier()\n",
        "                param_index += 3\n",
        "\n",
        "            qc_inst = qc.to_instruction()\n",
        "\n",
        "            qc = QuantumCircuit(num_qubits)\n",
        "            qc.append(qc_inst, range(num_qubits))\n",
        "            return qc\n",
        "\n",
        "        feature_map = ZFeatureMap(nbqbits)\n",
        "\n",
        "        ansatz = QuantumCircuit(nbqbits, name=\"Ansatz\")\n",
        "\n",
        "        # First Convolutional Layer\n",
        "        # ansatz.compose(conv_layer(nbqbits, \"c1\"), list(range(nbqbits)), inplace=True)\n",
        "        #\n",
        "        # # First Pooling Layer\n",
        "        # ansatz.compose(pool_layer([0, 1, 2, 3], [4, 5, 6, 7], \"p1\"), list(range(8)), inplace=True)\n",
        "\n",
        "        # Second Convolutional Layer\n",
        "        ansatz.compose(conv_layer(4, \"c2\"), list(range(0, 4)), inplace=True)\n",
        "\n",
        "        # Second Pooling Layer\n",
        "        ansatz.compose(pool_layer([0, 1], [2, 3], \"p2\"), list(range(0, 4)), inplace=True)\n",
        "\n",
        "        # Third Convolutional Layer\n",
        "\n",
        "        # Third Pooling Layer\n",
        "\n",
        "\n",
        "        # Combining the feature map and ansatz\n",
        "        circuit = QuantumCircuit(4)\n",
        "        circuit.compose(feature_map, range(4), inplace=True)\n",
        "        circuit.compose(ansatz, range(4), inplace=True)\n",
        "        circuit.x(list(range(4)))\n",
        "\n",
        "        observable = [Pauli('I' * i + 'Z' + 'I' * (4  - i - 1)) for i in range(2, 4)]\n",
        "\n",
        "\n",
        "        backend_options = {'method': 'statevector', 'max_parallel_threads': 4}\n",
        "        backend = AerSimulator(**backend_options)\n",
        "        circuit = transpile(circuit, backend=backend, optimization_level=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # we decompose the circuit for the QNN to avoid additional data copying\n",
        "        qnn = EstimatorQNN(\n",
        "            circuit=circuit,\n",
        "            observables=observable,\n",
        "            input_params=feature_map.parameters,\n",
        "            weight_params=ansatz.parameters,\n",
        "        )\n",
        "        return qnn\n",
        "\n",
        "\n",
        "def create_quantum_layer(nbqbitin,nbqbitout):\n",
        "    return quantum_layer(nbqbitin,nbqbitout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cflL7LelHuHi"
      },
      "outputs": [],
      "source": [
        "def quantum_noise(batch_size):\n",
        "    num_qubits = 1  # Utilisation d'un seul qubit pour le bruit\n",
        "    shots = 100  # Nombre de mesures (shots)\n",
        "\n",
        "    # Initialisation du générateur de nombres aléatoires quantiques\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    # Construction du circuit quantique avec une porte Hadamard\n",
        "    qc = QuantumCircuit(num_qubits, num_qubits)\n",
        "    qc.h(0)  # Application d'une porte Hadamard sur le qubit\n",
        "    qc.measure(0, 0)  # Mesure du qubit dans la base standard\n",
        "\n",
        "    # Exécution du circuit sur le simulateur\n",
        "    transpiled_circuit = transpile(qc, backend)\n",
        "    result = backend.run(transpiled_circuit, shots=shots * batch_size, memory=True).result()\n",
        "    # Extraction des résultats de mesure (0 ou 1)\n",
        "    memory = result.get_memory()\n",
        "\n",
        "    # Conversion des résultats en un tenseur PyTorch\n",
        "    # Remplacement des valeurs '0' et '1' par 0.0 et 1.0\n",
        "    noise = torch.tensor(\n",
        "        [1 if bit == '1' else 0 for bit in memory],\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Redimensionnement en [batch_size, shots]\n",
        "    noise = noise.view(batch_size, shots,1,1)\n",
        "\n",
        "    return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9EcMTqqH6mm",
        "outputId": "c0931b58-afff-4c33-c2d2-cea71077e8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ed897ec9b3d4>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load('/content/drive/MyDrive/generator_mnist_quantique_layer_noise.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]]]])\n",
            "tensor([[[[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[1.]],\n",
            "\n",
            "         [[0.]],\n",
            "\n",
            "         [[0.]]]])\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 512kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.32MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.63MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Generator, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.label_embedding = nn.Embedding(num_classes, 100)  # Embedding pour les classes\n",
        "        self.conv1 = torch.nn.utils.spectral_norm(nn.ConvTranspose2d(100 + 100, 112, 4, 1, 0))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(112)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.ConvTranspose2d(112, 56, 4, 2, 1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(56)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.conv3 = nn.ConvTranspose2d(56, 28, 4, 2, 1)\n",
        "        self.conv4 = nn.ConvTranspose2d(28, 1, 4, 2, 3)\n",
        "        self.lineaire = nn.Linear(28 * 28, 784)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        label_embedded = self.label_embedding(labels)  # Embedding de la classe\n",
        "        x = torch.cat((noise, label_embedded.unsqueeze(2).unsqueeze(3)), dim=1)  # Combine le bruit et l'embedding\n",
        "        x = self.conv1(x)\n",
        "        # print(x.size(),\"conv1\")\n",
        "        x = self.batchnorm1(x)\n",
        "        # print(x.size(),\"batchnorm1\")\n",
        "        x = self.relu1(x)\n",
        "        # print(x.size(),\"relu1\")\n",
        "        x = self.conv2(x)\n",
        "        # print(x.size(),\"conv2\")\n",
        "        x = self.batchnorm2(x)\n",
        "        # print(x.size(),\"batchnorm2\")\n",
        "        x = self.relu2(x)\n",
        "        # print(x.size(),\"relu2\")\n",
        "        x = self.conv3(x)\n",
        "        # print(x.size(),\"conv3\")\n",
        "        x = self.conv4(x)\n",
        "        # print(x.size(),\"conv4\")\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        self.savereseau()\n",
        "        return x\n",
        "\n",
        "    def savereseau(self):\n",
        "        torch.save(self.state_dict(), 'generator_mnist.pth')\n",
        "\n",
        "    def loadreseau(self):\n",
        "        self.load_state_dict(torch.load('/content/drive/MyDrive/generator_mnist_quantique_layer_noise.pth'))\n",
        "        self.eval()\n",
        "\n",
        "    def nb_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Bloc pour classer l'image\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(1600, 512)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 4)\n",
        "        self.quantum_layer=TorchConnector(create_quantum_layer(4,2).circuit)\n",
        "        self.fc_real_fake = nn.Linear(512, 1)  # Pour évaluer si l'image est réelle ou fausse\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Bloc de convolution et de pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Flatten et couches entièrement connectées\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        # Sorties\n",
        "        y = F.relu(self.fc2(x))\n",
        "        y=self.quantum_layer.forward(y)\n",
        "        class_output = F.log_softmax(y,\n",
        "                                     dim=1)  # Sortie pour la classification\n",
        "        real_fake_output = torch.sigmoid(self.fc_real_fake(x))  # Sortie pour vérifier si l'image est réelle\n",
        "        # print(real_fake_output)\n",
        "        return class_output, real_fake_output\n",
        "\n",
        "    def savereseau(self):\n",
        "        torch.save(self.state_dict(), 'discriminator_mnist.pth')\n",
        "\n",
        "    def loadreseau(self):\n",
        "        self.load_state_dict(torch.load('/content/drive/MyDrive/discriminator_mnist_quantique_layer_noise.pth'))\n",
        "        self.eval()\n",
        "\n",
        "    def nb_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def gradient_penalty(self, real_images, fake_images, batch_size):\n",
        "        # Interpolation between real and fake images\n",
        "        epsilon = torch.rand(batch_size, 1, 1, 1, device=real_images.device)\n",
        "        interpolated_images = epsilon * real_images + (1 - epsilon) * fake_images\n",
        "        interpolated_images.requires_grad_(True)\n",
        "\n",
        "        # Get discriminator output for interpolated images\n",
        "        _, interpolated_preds = self(interpolated_images)\n",
        "\n",
        "        # Calculate gradients of the discriminator output with respect to the interpolated images\n",
        "        gradients = autograd.grad(\n",
        "            outputs=interpolated_preds,\n",
        "            inputs=interpolated_images,\n",
        "            grad_outputs=torch.ones_like(interpolated_preds),\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "            only_inputs=True\n",
        "        )[0]\n",
        "\n",
        "        # Reshape gradients to calculate the norm\n",
        "        gradients = gradients.view(batch_size, -1)\n",
        "        gradients_norm = gradients.norm(2, dim=1)\n",
        "\n",
        "        # Calculate the gradient penalty\n",
        "        penalty = ((gradients_norm - 1) ** 2).mean()\n",
        "        return penalty\n",
        "\n",
        "\n",
        "def load_cifar10_data(n_samples=None, classes=None):\n",
        "    if classes is None:\n",
        "        classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "    X_train = datasets.MNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "    idx = np.isin(X_train.targets, classes)\n",
        "    X_train.data = X_train.data[idx][:n_samples]\n",
        "    X_train.targets = np.array(X_train.targets)[idx][:n_samples]\n",
        "\n",
        "    return X_train\n",
        "\n",
        "\n",
        "def create_dataloader(dataset, batch_size=1):\n",
        "    def collate_fn(batch):\n",
        "        images, targets = zip(*batch)\n",
        "        images = torch.stack(images)\n",
        "        targets = torch.tensor(targets, dtype=torch.long)  # Ensure targets are of type Long\n",
        "        return images, targets\n",
        "\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "def train(data_loader, resume,num_classes, epochs=10):\n",
        "    generator = Generator(num_classes=num_classes)\n",
        "    discriminator = Discriminator()\n",
        "    print(generator.nb_parameters())\n",
        "    print(discriminator.nb_parameters())\n",
        "    if resume:\n",
        "        generator.loadreseau()\n",
        "        discriminator.loadreseau()\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "    loss_fn_class = nn.CrossEntropyLoss()  # Pour les classes\n",
        "    loss_fn_real_fake = nn.BCELoss()  # Pour la vérification réelle/faux\n",
        "\n",
        "    # Liste pour stocker chaque type de perte\n",
        "    gen_loss_class_list = []\n",
        "    gen_loss_real_fake_list = []\n",
        "    disc_loss_class_real_list = []\n",
        "    # disc_loss_class_fake_list = []\n",
        "    disc_loss_real_fake_real_list = []\n",
        "    disc_loss_real_fake_fake_list = []\n",
        "    real_loss_class = 0\n",
        "    disc_loss_real_fake_real = 0\n",
        "    disc_loss_real_fake_fake = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        for nb, (real_images, real_labels) in enumerate(data_loader):\n",
        "\n",
        "            batch_size = real_images.size(0)  # Assurez-vous d'utiliser la taille du batch ici\n",
        "            noise = quantum_noise(batch_size)\n",
        "            torch_labels = real_labels.clone().detach().long()\n",
        "            # Générer des images fake avec le générateur\n",
        "            fake_images = generator(noise, torch_labels)\n",
        "            optimizer_disc.zero_grad()\n",
        "            if nb % 1 == 0:\n",
        "                # Entraînement du Discriminateur\n",
        "\n",
        "                real_class_preds, real_fake_preds = discriminator(real_images)\n",
        "                fake_class_preds, fake_fake_preds = discriminator(fake_images.detach())\n",
        "                real_loss_class = loss_fn_class(real_class_preds,\n",
        "                                                real_labels)  # À quel point l'image réelle est bien classifiée.\n",
        "                # fake_loss_class = loss_fn_class(fake_class_preds, real_labels)# a quelle point l'image fake est bien deviné\n",
        "                disc_loss_real_fake_real = loss_fn_real_fake(real_fake_preds, torch.full((batch_size, 1),\n",
        "                                                                                         0.9))  # a quelle point l'image reel a bien été deviné reel\n",
        "                disc_loss_real_fake_fake = loss_fn_real_fake(fake_fake_preds, torch.full((batch_size, 1),\n",
        "                                                                                         0.1))  # a quelle point l'image fake a bien été deviné fake\n",
        "                gradient_penalty = discriminator.gradient_penalty(real_images, fake_images, batch_size)\n",
        "\n",
        "                disc_loss = real_loss_class + disc_loss_real_fake_real + disc_loss_real_fake_fake + gradient_penalty\n",
        "                disc_loss.backward(retain_graph=True)\n",
        "                optimizer_disc.step()\n",
        "\n",
        "            # Entraînement du Générateur\n",
        "            optimizer_gen.zero_grad()\n",
        "            fake_class_preds, fake_fake_preds = discriminator(fake_images)\n",
        "            gen_loss_class = loss_fn_class(fake_class_preds, real_labels)\n",
        "            gen_loss_real_fake = loss_fn_real_fake(fake_fake_preds, torch.full((batch_size, 1), 0.9))\n",
        "            gen_loss = gen_loss_class + gen_loss_real_fake\n",
        "            gen_loss.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            # Enregistrement des pertes individuelles\n",
        "            gen_loss_class_list.append(gen_loss_class.item())  #\n",
        "            gen_loss_real_fake_list.append(gen_loss_real_fake.item())\n",
        "            disc_loss_class_real_list.append(real_loss_class.item())\n",
        "            # disc_loss_class_fake_list.append(fake_loss_class.item())\n",
        "            disc_loss_real_fake_real_list.append(disc_loss_real_fake_real.item())\n",
        "            disc_loss_real_fake_fake_list.append(disc_loss_real_fake_fake.item())\n",
        "        end_time = time.time()\n",
        "        generator.savereseau()\n",
        "        discriminator.savereseau()\n",
        "        print(\n",
        "            f\"Epoch [{epoch + 1}/{epochs}], Discriminator Loss: {disc_loss.item()}, Generator Loss: {gen_loss.item()},image par seconde: {len(data_loader.dataset) / (end_time - start_time)}\")\n",
        "\n",
        "    # Affichage des courbes des différentes pertes\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Affichage des pertes sous forme de points\n",
        "    plt.scatter(range(len(gen_loss_class_list)), gen_loss_class_list, label=\"Generator Classification Loss\", s=10)\n",
        "    plt.scatter(range(len(gen_loss_real_fake_list)), gen_loss_real_fake_list, label=\"Generator Real/Fake Loss\", s=10)\n",
        "    plt.scatter(range(len(disc_loss_class_real_list)), disc_loss_class_real_list,\n",
        "                label=\"Discriminator Real Classification Loss\", s=10)\n",
        "    plt.scatter(range(len(disc_loss_real_fake_real_list)), disc_loss_real_fake_real_list,\n",
        "                label=\"Discriminator Real Real/Fake Loss\", s=10)\n",
        "    plt.scatter(range(len(disc_loss_real_fake_fake_list)), disc_loss_real_fake_fake_list,\n",
        "                label=\"Discriminator Fake Real/Fake Loss\", s=10)\n",
        "\n",
        "    # Étiquettes et légende\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Sauvegarde des modèles\n",
        "\n",
        "\n",
        "\n",
        "def test(generator, num_classes):\n",
        "    generator.eval()\n",
        "    images_per_class = 1  # Nombre d'images à générer par classe\n",
        "\n",
        "    # Créer un tableau pour stocker les images générées\n",
        "    generated_images = []\n",
        "\n",
        "    # Générer une image pour chaque classe\n",
        "    for class_label in range(num_classes):\n",
        "        noise = quantum_noise(images_per_class)\n",
        "        print(noise)\n",
        "        class_tensor = torch.tensor([class_label])\n",
        "        fake_image = generator(noise, class_tensor)  # Générer l'image\n",
        "        generated_images.append(fake_image)\n",
        "\n",
        "    # Convertir la liste en un tenseur\n",
        "\n",
        "    generated_images = torch.cat(generated_images)\n",
        "\n",
        "    # Load a sample image from the dataset\n",
        "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "    sample_images = [dataset[i][0] for i in range(num_classes)]\n",
        "\n",
        "    # Visualize the images\n",
        "    fig, axes = plt.subplots(2, num_classes, figsize=(num_classes * 3, 6))\n",
        "    for i in range(num_classes):\n",
        "        # Display generated images\n",
        "        img = generated_images[i]\n",
        "        axes[0, i].imshow(img.detach().cpu().numpy().squeeze())\n",
        "        axes[0, i].set_title(f'Generated Class {i}')\n",
        "        axes[0, i].set_xticks([])\n",
        "        axes[0, i].set_yticks([])\n",
        "\n",
        "        # Display sample images from the dataset\n",
        "        sample_img = sample_images[i]\n",
        "        axes[1, i].imshow(sample_img.numpy().squeeze())\n",
        "        axes[1, i].set_title(f'Sample Class {i}')\n",
        "        axes[1, i].set_xticks([])\n",
        "        axes[1, i].set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main(mode=\"train\"):\n",
        "    batch_size = 5  # nb imaga par batch\n",
        "    nb_image_by_batch = 500 # nb image étudier\n",
        "    classes = [0, 1]\n",
        "    epochs = 10\n",
        "    if mode == \"train\":\n",
        "        data = load_cifar10_data(n_samples=nb_image_by_batch,classes=classes)\n",
        "        data = create_dataloader(data, batch_size=batch_size)\n",
        "\n",
        "        train(data, epochs=epochs,num_classes=len(classes),resume=False)\n",
        "    elif mode == \"re\":\n",
        "        data = load_cifar10_data(n_samples=nb_image_by_batch,classes=classes)\n",
        "        data = create_dataloader(data, batch_size=batch_size)\n",
        "        train(data, epochs=epochs, resume=True,num_classes=len(classes))  # Reprendre l'entraînement\n",
        "    elif mode == \"save\":\n",
        "      # 1. Recréer le générateur et le discriminateur avec le bon nombre de classes\n",
        "      generator = Generator(num_classes=len(classes))\n",
        "      discriminator = Discriminator()\n",
        "\n",
        "      # 2. Charger les modèles depuis la mémoire de la VM\n",
        "      generator.loadreseau() # Assurez-vous que loadreseau() charge depuis le bon chemin\n",
        "      discriminator.loadreseau()\n",
        "\n",
        "      # 3. Sauvegarder sur Google Drive\n",
        "      save_to_drive(generator, discriminator)\n",
        "    else:\n",
        "        generator = Generator(num_classes=len(classes))\n",
        "        generator.loadreseau()\n",
        "        test(generator, num_classes=len(classes))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mode = \"test\"\n",
        "    torch.manual_seed(time.time())\n",
        "\n",
        "    main(mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XM5EOu9G9Hi"
      },
      "outputs": [],
      "source": [
        "def save_to_drive(generator, discriminator):\n",
        "    \"\"\"Sauvegarde les modèles sur Google Drive.\"\"\"\n",
        "    drive.mount('/content/drive')\n",
        "    save_path_gen = '/content/drive/MyDrive/generator_mnist_quantique_layer_noise.pth'\n",
        "    save_path_disc = '/content/drive/MyDrive/discriminator_mnist_quantique_layer_noise.pth'\n",
        "\n",
        "    torch.save(generator.state_dict(), save_path_gen)\n",
        "    torch.save(discriminator.state_dict(), save_path_disc)\n",
        "\n",
        "    print(f\"Generator saved to: {save_path_gen}\")\n",
        "    print(f\"Discriminator saved to: {save_path_disc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "SZMXS36S_mQz",
        "outputId": "d9a2953f-f7fc-43a1-a91c-2baa21d63544"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ddf5d8759969>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/generator_mnist_quantique_layer_noise.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/discriminator_mnist_quantique_layer_noise.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model saved to Google Drive at: {save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "torch.save(generator.state_dict(), '/content/drive/MyDrive/generator_mnist_quantique_layer_noise.pth')\n",
        "torch.save(discriminator.state_dict(), '/content/drive/MyDrive/discriminator_mnist_quantique_layer_noise.pth')\n",
        "\n",
        "print(f\"Model saved to Google Drive at: {save_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}